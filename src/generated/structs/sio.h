/**
 * \file
 * \brief Generated by ifgen (3.1.6).
 */
#pragma once

#include "../ifgen/common.h"

namespace RP2040
{

/**
 * Single-cycle IO block\n
 *         Provides core-local and inter-core hardware for the two processors,
 * with single-cycle access.
 */
struct [[gnu::packed]] sio
{
    /* Constant attributes. */
    static constexpr std::size_t size = 384; /*!< sio's size in bytes. */

    /* Fields. */
    uint32_t CPUID;              /*!< (read-write) Processor core identifier\n
      Value is 0 when read from processor core 0, and 1 when read from processor
             core 1. */
    const uint32_t GPIO_IN = {}; /*!< (read-only) Input value for GPIO pins */
    const uint32_t GPIO_HI_IN =
        {}; /*!< (read-only) Input value for QSPI pins */
    const uint32_t reserved_padding0 = {};
    uint32_t GPIO_OUT;        /*!< (read-write) GPIO output value */
    uint32_t GPIO_OUT_SET;    /*!< (write-only) GPIO output value set */
    uint32_t GPIO_OUT_CLR;    /*!< (write-only) GPIO output value clear */
    uint32_t GPIO_OUT_XOR;    /*!< (write-only) GPIO output value XOR */
    uint32_t GPIO_OE;         /*!< (read-write) GPIO output enable */
    uint32_t GPIO_OE_SET;     /*!< (write-only) GPIO output enable set */
    uint32_t GPIO_OE_CLR;     /*!< (write-only) GPIO output enable clear */
    uint32_t GPIO_OE_XOR;     /*!< (write-only) GPIO output enable XOR */
    uint32_t GPIO_HI_OUT;     /*!< (read-write) QSPI output value */
    uint32_t GPIO_HI_OUT_SET; /*!< (write-only) QSPI output value set */
    uint32_t GPIO_HI_OUT_CLR; /*!< (write-only) QSPI output value clear */
    uint32_t GPIO_HI_OUT_XOR; /*!< (write-only) QSPI output value XOR */
    uint32_t GPIO_HI_OE;      /*!< (read-write) QSPI output enable */
    uint32_t GPIO_HI_OE_SET;  /*!< (write-only) QSPI output enable set */
    uint32_t GPIO_HI_OE_CLR;  /*!< (write-only) QSPI output enable clear */
    uint32_t GPIO_HI_OE_XOR;  /*!< (write-only) QSPI output enable XOR */
    uint32_t FIFO_ST; /*!< (read-write) Status register for inter-core FIFOs
(mailboxes).\n There is one FIFO in the core 0 -> core 1 direction, and one
core 1 -> core 0. Both are 32 bits wide and 8 words deep.\n Core 0 can see the
read side of the 1->0 FIFO (RX), and the write side of 0->1 FIFO (TX).\n Core 1
can see the read side of the 0->1 FIFO (RX), and the write side of 1->0 FIFO
(TX).\n The SIO IRQ for each core is the logical OR of the VLD, WOF and ROE
fields of its FIFO_ST register. */
    uint32_t FIFO_WR; /*!< (read-write) Write access to this core's TX FIFO */
    uint32_t FIFO_RD; /*!< (read-write) Read access to this core's RX FIFO */
    uint32_t SPINLOCK_ST;   /*!< (read-write) Spinlock state\n
 A bitmap containing the state of all 32 spinlocks (1=locked).\n
 Mainly intended for debugging. */
    uint32_t DIV_UDIVIDEND; /*!< (read-write) Divider unsigned dividend\n
 Write to the DIVIDEND operand of the divider, i.e. the p in `p / q`.\n
 Any operand write starts a new calculation. The results appear in QUOTIENT,
 REMAINDER.\n UDIVIDEND/SDIVIDEND are aliases of the same internal register.
 The U alias starts an\n unsigned calculation, and the S alias starts a signed
 calculation. */
    uint32_t DIV_UDIVISOR;  /*!< (read-write) Divider unsigned divisor\n
 Write to the DIVISOR operand of the divider, i.e. the q in `p / q`.\n
 Any operand write starts a new calculation. The results appear in QUOTIENT,
 REMAINDER.\n  UDIVISOR/SDIVISOR are aliases of the same internal register. The
 U  alias starts an\n  unsigned calculation, and the S alias starts a signed
 calculation. */
    uint32_t DIV_SDIVIDEND; /*!< (read-write) Divider signed dividend\n
 The same as UDIVIDEND, but starts a signed calculation, rather than unsigned.
 */
    uint32_t DIV_SDIVISOR;  /*!< (read-write) Divider signed divisor\n
 The same as UDIVISOR, but starts a signed calculation, rather than unsigned. */
    uint32_t DIV_QUOTIENT;  /*!< (read-write) Divider result quotient\n
 The result of `DIVIDEND / DIVISOR` (division). Contents undefined while
 CSR_READY is low.\n  For signed calculations, QUOTIENT is negative when the
 signs of DIVIDEND and DIVISOR differ.\n  This register can be written to
 directly, for context save/restore purposes. This halts any\n  in-progress
 calculation and sets the CSR_READY and CSR_DIRTY flags.\n  Reading from
 QUOTIENT  clears the CSR_DIRTY flag, so should read results in the order\n
 REMAINDER,  QUOTIENT if CSR_DIRTY is used. */
    uint32_t DIV_REMAINDER; /*!< (read-write) Divider result remainder\n
 The result of `DIVIDEND % DIVISOR` (modulo). Contents undefined while
 CSR_READY is low.\n For signed calculations, REMAINDER is negative only when
 DIVIDEND is negative.\n This register can be written to directly, for context
 save/restore purposes. This halts any\n in-progress calculation and sets the
 CSR_READY and CSR_DIRTY flags. */
    const uint32_t DIV_CSR =
        {}; /*!< (read-only) Control and status register for divider. */
    const uint32_t reserved_padding1 = {};
    uint32_t
        INTERP0_ACCUM0; /*!< (read-write) Read/write access to accumulator 0 */
    uint32_t
        INTERP0_ACCUM1; /*!< (read-write) Read/write access to accumulator 1 */
    uint32_t INTERP0_BASE0;      /*!< (read-write) Read/write access to BASE0
                                    register. */
    uint32_t INTERP0_BASE1;      /*!< (read-write) Read/write access to BASE1
                                    register. */
    uint32_t INTERP0_BASE2;      /*!< (read-write) Read/write access to BASE2
                                    register. */
    uint32_t INTERP0_POP_LANE0;  /*!< (read-write) Read LANE0 result, and
                                    simultaneously write lane results to both
                                    accumulators (POP). */
    uint32_t INTERP0_POP_LANE1;  /*!< (read-write) Read LANE1 result, and
                                    simultaneously write lane results to both
                                    accumulators (POP). */
    uint32_t INTERP0_POP_FULL;   /*!< (read-write) Read FULL result, and
                                    simultaneously write lane results to both
                                    accumulators (POP). */
    uint32_t INTERP0_PEEK_LANE0; /*!< (read-write) Read LANE0 result, without
                                    altering any internal state (PEEK). */
    uint32_t INTERP0_PEEK_LANE1; /*!< (read-write) Read LANE1 result, without
                                    altering any internal state (PEEK). */
    uint32_t INTERP0_PEEK_FULL;  /*!< (read-write) Read FULL result, without
                                    altering any internal state (PEEK). */
    uint32_t
        INTERP0_CTRL_LANE0; /*!< (read-write) Control register for lane 0 */
    uint32_t
        INTERP0_CTRL_LANE1; /*!< (read-write) Control register for lane 1 */
    uint32_t INTERP0_ACCUM0_ADD; /*!< (read-write) Values written here are
      atomically added to ACCUM0\n Reading yields lane 0's raw shift and mask
      value (BASE0 not added). */
    uint32_t INTERP0_ACCUM1_ADD; /*!< (read-write) Values written here are
      atomically added to ACCUM1\n Reading yields lane 1's raw shift and mask
      value (BASE1 not added). */
    uint32_t INTERP0_BASE_1AND0; /*!< (read-write) On write, the lower 16 bits
      go to BASE0, upper bits to BASE1 simultaneously.\n Each half is
      sign-extended to 32 bits if that lane's SIGNED flag is set. */
    uint32_t
        INTERP1_ACCUM0; /*!< (read-write) Read/write access to accumulator 0 */
    uint32_t
        INTERP1_ACCUM1; /*!< (read-write) Read/write access to accumulator 1 */
    uint32_t INTERP1_BASE0;      /*!< (read-write) Read/write access to BASE0
                                    register. */
    uint32_t INTERP1_BASE1;      /*!< (read-write) Read/write access to BASE1
                                    register. */
    uint32_t INTERP1_BASE2;      /*!< (read-write) Read/write access to BASE2
                                    register. */
    uint32_t INTERP1_POP_LANE0;  /*!< (read-write) Read LANE0 result, and
                                    simultaneously write lane results to both
                                    accumulators (POP). */
    uint32_t INTERP1_POP_LANE1;  /*!< (read-write) Read LANE1 result, and
                                    simultaneously write lane results to both
                                    accumulators (POP). */
    uint32_t INTERP1_POP_FULL;   /*!< (read-write) Read FULL result, and
                                    simultaneously write lane results to both
                                    accumulators (POP). */
    uint32_t INTERP1_PEEK_LANE0; /*!< (read-write) Read LANE0 result, without
                                    altering any internal state (PEEK). */
    uint32_t INTERP1_PEEK_LANE1; /*!< (read-write) Read LANE1 result, without
                                    altering any internal state (PEEK). */
    uint32_t INTERP1_PEEK_FULL;  /*!< (read-write) Read FULL result, without
                                    altering any internal state (PEEK). */
    uint32_t
        INTERP1_CTRL_LANE0; /*!< (read-write) Control register for lane 0 */
    uint32_t
        INTERP1_CTRL_LANE1; /*!< (read-write) Control register for lane 1 */
    uint32_t INTERP1_ACCUM0_ADD; /*!< (read-write) Values written here are
      atomically added to ACCUM0\n Reading yields lane 0's raw shift and mask
      value (BASE0 not added). */
    uint32_t INTERP1_ACCUM1_ADD; /*!< (read-write) Values written here are
      atomically added to ACCUM1\n Reading yields lane 1's raw shift and mask
      value (BASE1 not added). */
    uint32_t INTERP1_BASE_1AND0; /*!< (read-write) On write, the lower 16 bits
      go to BASE0, upper bits to BASE1 simultaneously.\n Each half is
      sign-extended to 32 bits if that lane's SIGNED flag is set. */
    uint32_t
        SPINLOCK0; /*!< (read-write) Reading from a spinlock address will:\n
- Return 0 if lock is already locked\n
- Otherwise return nonzero, and simultaneously claim the lock\n\n
Writing (any value) releases the lock.\n
If core 0 and core 1 attempt to claim the same lock simultaneously, core 0
wins.\n The value returned on success is 0x1 << lock number. */
    uint32_t
        SPINLOCK1; /*!< (read-write) Reading from a spinlock address will:\n
- Return 0 if lock is already locked\n
- Otherwise return nonzero, and simultaneously claim the lock\n\n
Writing (any value) releases the lock.\n
If core 0 and core 1 attempt to claim the same lock simultaneously, core 0
wins.\n The value returned on success is 0x1 << lock number. */
    uint32_t
        SPINLOCK2; /*!< (read-write) Reading from a spinlock address will:\n
- Return 0 if lock is already locked\n
- Otherwise return nonzero, and simultaneously claim the lock\n\n
Writing (any value) releases the lock.\n
If core 0 and core 1 attempt to claim the same lock simultaneously, core 0
wins.\n The value returned on success is 0x1 << lock number. */
    uint32_t
        SPINLOCK3; /*!< (read-write) Reading from a spinlock address will:\n
- Return 0 if lock is already locked\n
- Otherwise return nonzero, and simultaneously claim the lock\n\n
Writing (any value) releases the lock.\n
If core 0 and core 1 attempt to claim the same lock simultaneously, core 0
wins.\n The value returned on success is 0x1 << lock number. */
    uint32_t
        SPINLOCK4; /*!< (read-write) Reading from a spinlock address will:\n
- Return 0 if lock is already locked\n
- Otherwise return nonzero, and simultaneously claim the lock\n\n
Writing (any value) releases the lock.\n
If core 0 and core 1 attempt to claim the same lock simultaneously, core 0
wins.\n The value returned on success is 0x1 << lock number. */
    uint32_t
        SPINLOCK5; /*!< (read-write) Reading from a spinlock address will:\n
- Return 0 if lock is already locked\n
- Otherwise return nonzero, and simultaneously claim the lock\n\n
Writing (any value) releases the lock.\n
If core 0 and core 1 attempt to claim the same lock simultaneously, core 0
wins.\n The value returned on success is 0x1 << lock number. */
    uint32_t
        SPINLOCK6; /*!< (read-write) Reading from a spinlock address will:\n
- Return 0 if lock is already locked\n
- Otherwise return nonzero, and simultaneously claim the lock\n\n
Writing (any value) releases the lock.\n
If core 0 and core 1 attempt to claim the same lock simultaneously, core 0
wins.\n The value returned on success is 0x1 << lock number. */
    uint32_t
        SPINLOCK7; /*!< (read-write) Reading from a spinlock address will:\n
- Return 0 if lock is already locked\n
- Otherwise return nonzero, and simultaneously claim the lock\n\n
Writing (any value) releases the lock.\n
If core 0 and core 1 attempt to claim the same lock simultaneously, core 0
wins.\n The value returned on success is 0x1 << lock number. */
    uint32_t
        SPINLOCK8; /*!< (read-write) Reading from a spinlock address will:\n
- Return 0 if lock is already locked\n
- Otherwise return nonzero, and simultaneously claim the lock\n\n
Writing (any value) releases the lock.\n
If core 0 and core 1 attempt to claim the same lock simultaneously, core 0
wins.\n The value returned on success is 0x1 << lock number. */
    uint32_t
        SPINLOCK9; /*!< (read-write) Reading from a spinlock address will:\n
- Return 0 if lock is already locked\n
- Otherwise return nonzero, and simultaneously claim the lock\n\n
Writing (any value) releases the lock.\n
If core 0 and core 1 attempt to claim the same lock simultaneously, core 0
wins.\n The value returned on success is 0x1 << lock number. */
    uint32_t
        SPINLOCK10; /*!< (read-write) Reading from a spinlock address will:\n
- Return 0 if lock is already locked\n
- Otherwise return nonzero, and simultaneously claim the lock\n\n
Writing (any value) releases the lock.\n
If core 0 and core 1 attempt to claim the same lock simultaneously, core 0
wins.\n The value returned on success is 0x1 << lock number. */
    uint32_t
        SPINLOCK11; /*!< (read-write) Reading from a spinlock address will:\n
- Return 0 if lock is already locked\n
- Otherwise return nonzero, and simultaneously claim the lock\n\n
Writing (any value) releases the lock.\n
If core 0 and core 1 attempt to claim the same lock simultaneously, core 0
wins.\n The value returned on success is 0x1 << lock number. */
    uint32_t
        SPINLOCK12; /*!< (read-write) Reading from a spinlock address will:\n
- Return 0 if lock is already locked\n
- Otherwise return nonzero, and simultaneously claim the lock\n\n
Writing (any value) releases the lock.\n
If core 0 and core 1 attempt to claim the same lock simultaneously, core 0
wins.\n The value returned on success is 0x1 << lock number. */
    uint32_t
        SPINLOCK13; /*!< (read-write) Reading from a spinlock address will:\n
- Return 0 if lock is already locked\n
- Otherwise return nonzero, and simultaneously claim the lock\n\n
Writing (any value) releases the lock.\n
If core 0 and core 1 attempt to claim the same lock simultaneously, core 0
wins.\n The value returned on success is 0x1 << lock number. */
    uint32_t
        SPINLOCK14; /*!< (read-write) Reading from a spinlock address will:\n
- Return 0 if lock is already locked\n
- Otherwise return nonzero, and simultaneously claim the lock\n\n
Writing (any value) releases the lock.\n
If core 0 and core 1 attempt to claim the same lock simultaneously, core 0
wins.\n The value returned on success is 0x1 << lock number. */
    uint32_t
        SPINLOCK15; /*!< (read-write) Reading from a spinlock address will:\n
- Return 0 if lock is already locked\n
- Otherwise return nonzero, and simultaneously claim the lock\n\n
Writing (any value) releases the lock.\n
If core 0 and core 1 attempt to claim the same lock simultaneously, core 0
wins.\n The value returned on success is 0x1 << lock number. */
    uint32_t
        SPINLOCK16; /*!< (read-write) Reading from a spinlock address will:\n
- Return 0 if lock is already locked\n
- Otherwise return nonzero, and simultaneously claim the lock\n\n
Writing (any value) releases the lock.\n
If core 0 and core 1 attempt to claim the same lock simultaneously, core 0
wins.\n The value returned on success is 0x1 << lock number. */
    uint32_t
        SPINLOCK17; /*!< (read-write) Reading from a spinlock address will:\n
- Return 0 if lock is already locked\n
- Otherwise return nonzero, and simultaneously claim the lock\n\n
Writing (any value) releases the lock.\n
If core 0 and core 1 attempt to claim the same lock simultaneously, core 0
wins.\n The value returned on success is 0x1 << lock number. */
    uint32_t
        SPINLOCK18; /*!< (read-write) Reading from a spinlock address will:\n
- Return 0 if lock is already locked\n
- Otherwise return nonzero, and simultaneously claim the lock\n\n
Writing (any value) releases the lock.\n
If core 0 and core 1 attempt to claim the same lock simultaneously, core 0
wins.\n The value returned on success is 0x1 << lock number. */
    uint32_t
        SPINLOCK19; /*!< (read-write) Reading from a spinlock address will:\n
- Return 0 if lock is already locked\n
- Otherwise return nonzero, and simultaneously claim the lock\n\n
Writing (any value) releases the lock.\n
If core 0 and core 1 attempt to claim the same lock simultaneously, core 0
wins.\n The value returned on success is 0x1 << lock number. */
    uint32_t
        SPINLOCK20; /*!< (read-write) Reading from a spinlock address will:\n
- Return 0 if lock is already locked\n
- Otherwise return nonzero, and simultaneously claim the lock\n\n
Writing (any value) releases the lock.\n
If core 0 and core 1 attempt to claim the same lock simultaneously, core 0
wins.\n The value returned on success is 0x1 << lock number. */
    uint32_t
        SPINLOCK21; /*!< (read-write) Reading from a spinlock address will:\n
- Return 0 if lock is already locked\n
- Otherwise return nonzero, and simultaneously claim the lock\n\n
Writing (any value) releases the lock.\n
If core 0 and core 1 attempt to claim the same lock simultaneously, core 0
wins.\n The value returned on success is 0x1 << lock number. */
    uint32_t
        SPINLOCK22; /*!< (read-write) Reading from a spinlock address will:\n
- Return 0 if lock is already locked\n
- Otherwise return nonzero, and simultaneously claim the lock\n\n
Writing (any value) releases the lock.\n
If core 0 and core 1 attempt to claim the same lock simultaneously, core 0
wins.\n The value returned on success is 0x1 << lock number. */
    uint32_t
        SPINLOCK23; /*!< (read-write) Reading from a spinlock address will:\n
- Return 0 if lock is already locked\n
- Otherwise return nonzero, and simultaneously claim the lock\n\n
Writing (any value) releases the lock.\n
If core 0 and core 1 attempt to claim the same lock simultaneously, core 0
wins.\n The value returned on success is 0x1 << lock number. */
    uint32_t
        SPINLOCK24; /*!< (read-write) Reading from a spinlock address will:\n
- Return 0 if lock is already locked\n
- Otherwise return nonzero, and simultaneously claim the lock\n\n
Writing (any value) releases the lock.\n
If core 0 and core 1 attempt to claim the same lock simultaneously, core 0
wins.\n The value returned on success is 0x1 << lock number. */
    uint32_t
        SPINLOCK25; /*!< (read-write) Reading from a spinlock address will:\n
- Return 0 if lock is already locked\n
- Otherwise return nonzero, and simultaneously claim the lock\n\n
Writing (any value) releases the lock.\n
If core 0 and core 1 attempt to claim the same lock simultaneously, core 0
wins.\n The value returned on success is 0x1 << lock number. */
    uint32_t
        SPINLOCK26; /*!< (read-write) Reading from a spinlock address will:\n
- Return 0 if lock is already locked\n
- Otherwise return nonzero, and simultaneously claim the lock\n\n
Writing (any value) releases the lock.\n
If core 0 and core 1 attempt to claim the same lock simultaneously, core 0
wins.\n The value returned on success is 0x1 << lock number. */
    uint32_t
        SPINLOCK27; /*!< (read-write) Reading from a spinlock address will:\n
- Return 0 if lock is already locked\n
- Otherwise return nonzero, and simultaneously claim the lock\n\n
Writing (any value) releases the lock.\n
If core 0 and core 1 attempt to claim the same lock simultaneously, core 0
wins.\n The value returned on success is 0x1 << lock number. */
    uint32_t
        SPINLOCK28; /*!< (read-write) Reading from a spinlock address will:\n
- Return 0 if lock is already locked\n
- Otherwise return nonzero, and simultaneously claim the lock\n\n
Writing (any value) releases the lock.\n
If core 0 and core 1 attempt to claim the same lock simultaneously, core 0
wins.\n The value returned on success is 0x1 << lock number. */
    uint32_t
        SPINLOCK29; /*!< (read-write) Reading from a spinlock address will:\n
- Return 0 if lock is already locked\n
- Otherwise return nonzero, and simultaneously claim the lock\n\n
Writing (any value) releases the lock.\n
If core 0 and core 1 attempt to claim the same lock simultaneously, core 0
wins.\n The value returned on success is 0x1 << lock number. */
    uint32_t
        SPINLOCK30; /*!< (read-write) Reading from a spinlock address will:\n
- Return 0 if lock is already locked\n
- Otherwise return nonzero, and simultaneously claim the lock\n\n
Writing (any value) releases the lock.\n
If core 0 and core 1 attempt to claim the same lock simultaneously, core 0
wins.\n The value returned on success is 0x1 << lock number. */
    uint32_t
        SPINLOCK31; /*!< (read-write) Reading from a spinlock address will:\n
- Return 0 if lock is already locked\n
- Otherwise return nonzero, and simultaneously claim the lock\n\n
Writing (any value) releases the lock.\n
If core 0 and core 1 attempt to claim the same lock simultaneously, core 0
wins.\n The value returned on success is 0x1 << lock number. */

    /* Methods. */

    /**
     * Get GPIO_IN's GPIO_IN field.
     */
    inline uint32_t get_GPIO_IN_GPIO_IN() volatile
    {
        return (GPIO_IN >> 0u) & 0b111111111111111111111111111111u;
    }

    /**
     * Get GPIO_HI_IN's GPIO_HI_IN field.
     */
    inline uint8_t get_GPIO_HI_IN_GPIO_HI_IN() volatile
    {
        return (GPIO_HI_IN >> 0u) & 0b111111u;
    }

    /**
     * Get GPIO_OUT's GPIO_OUT field.
     */
    inline uint32_t get_GPIO_OUT_GPIO_OUT() volatile
    {
        return (GPIO_OUT >> 0u) & 0b111111111111111111111111111111u;
    }

    /**
     * Set GPIO_OUT's GPIO_OUT field.
     *
     * Set output level (1/0 -> high/low) for GPIO0...29.\n
     *                 Reading back gives the last value written, NOT the input
     * value from the pins.\n If core 0 and core 1 both write to GPIO_OUT
     * simultaneously (or to a SET/CLR/XOR alias),\n the result is as though
     * the write from core 0 took place first,\n and the write from core 1 was
     * then applied to that intermediate result.
     */
    inline void set_GPIO_OUT_GPIO_OUT(uint32_t value) volatile
    {
        uint32_t curr = GPIO_OUT;

        curr &= ~(0b111111111111111111111111111111u << 0u);
        curr |= (value & 0b111111111111111111111111111111u) << 0u;

        GPIO_OUT = curr;
    }

    /**
     * Set GPIO_OUT_SET's GPIO_OUT_SET field.
     *
     * Perform an atomic bit-set on GPIO_OUT, i.e. `GPIO_OUT |= wdata`
     */
    inline void set_GPIO_OUT_SET_GPIO_OUT_SET(uint32_t value) volatile
    {
        uint32_t curr = GPIO_OUT_SET;

        curr &= ~(0b111111111111111111111111111111u << 0u);
        curr |= (value & 0b111111111111111111111111111111u) << 0u;

        GPIO_OUT_SET = curr;
    }

    /**
     * Set GPIO_OUT_CLR's GPIO_OUT_CLR field.
     *
     * Perform an atomic bit-clear on GPIO_OUT, i.e. `GPIO_OUT &= ~wdata`
     */
    inline void set_GPIO_OUT_CLR_GPIO_OUT_CLR(uint32_t value) volatile
    {
        uint32_t curr = GPIO_OUT_CLR;

        curr &= ~(0b111111111111111111111111111111u << 0u);
        curr |= (value & 0b111111111111111111111111111111u) << 0u;

        GPIO_OUT_CLR = curr;
    }

    /**
     * Set GPIO_OUT_XOR's GPIO_OUT_XOR field.
     *
     * Perform an atomic bitwise XOR on GPIO_OUT, i.e. `GPIO_OUT ^= wdata`
     */
    inline void set_GPIO_OUT_XOR_GPIO_OUT_XOR(uint32_t value) volatile
    {
        uint32_t curr = GPIO_OUT_XOR;

        curr &= ~(0b111111111111111111111111111111u << 0u);
        curr |= (value & 0b111111111111111111111111111111u) << 0u;

        GPIO_OUT_XOR = curr;
    }

    /**
     * Get GPIO_OE's GPIO_OE field.
     */
    inline uint32_t get_GPIO_OE_GPIO_OE() volatile
    {
        return (GPIO_OE >> 0u) & 0b111111111111111111111111111111u;
    }

    /**
     * Set GPIO_OE's GPIO_OE field.
     *
     * Set output enable (1/0 -> output/input) for GPIO0...29.\n
     *                 Reading back gives the last value written.\n
     *                 If core 0 and core 1 both write to GPIO_OE
     * simultaneously (or to a SET/CLR/XOR alias),\n the result is as though
     * the write from core 0 took place first,\n and the write from core 1 was
     * then applied to that intermediate result.
     */
    inline void set_GPIO_OE_GPIO_OE(uint32_t value) volatile
    {
        uint32_t curr = GPIO_OE;

        curr &= ~(0b111111111111111111111111111111u << 0u);
        curr |= (value & 0b111111111111111111111111111111u) << 0u;

        GPIO_OE = curr;
    }

    /**
     * Set GPIO_OE_SET's GPIO_OE_SET field.
     *
     * Perform an atomic bit-set on GPIO_OE, i.e. `GPIO_OE |= wdata`
     */
    inline void set_GPIO_OE_SET_GPIO_OE_SET(uint32_t value) volatile
    {
        uint32_t curr = GPIO_OE_SET;

        curr &= ~(0b111111111111111111111111111111u << 0u);
        curr |= (value & 0b111111111111111111111111111111u) << 0u;

        GPIO_OE_SET = curr;
    }

    /**
     * Set GPIO_OE_CLR's GPIO_OE_CLR field.
     *
     * Perform an atomic bit-clear on GPIO_OE, i.e. `GPIO_OE &= ~wdata`
     */
    inline void set_GPIO_OE_CLR_GPIO_OE_CLR(uint32_t value) volatile
    {
        uint32_t curr = GPIO_OE_CLR;

        curr &= ~(0b111111111111111111111111111111u << 0u);
        curr |= (value & 0b111111111111111111111111111111u) << 0u;

        GPIO_OE_CLR = curr;
    }

    /**
     * Set GPIO_OE_XOR's GPIO_OE_XOR field.
     *
     * Perform an atomic bitwise XOR on GPIO_OE, i.e. `GPIO_OE ^= wdata`
     */
    inline void set_GPIO_OE_XOR_GPIO_OE_XOR(uint32_t value) volatile
    {
        uint32_t curr = GPIO_OE_XOR;

        curr &= ~(0b111111111111111111111111111111u << 0u);
        curr |= (value & 0b111111111111111111111111111111u) << 0u;

        GPIO_OE_XOR = curr;
    }

    /**
     * Get GPIO_HI_OUT's GPIO_HI_OUT field.
     */
    inline uint8_t get_GPIO_HI_OUT_GPIO_HI_OUT() volatile
    {
        return (GPIO_HI_OUT >> 0u) & 0b111111u;
    }

    /**
     * Set GPIO_HI_OUT's GPIO_HI_OUT field.
     *
     * Set output level (1/0 -> high/low) for QSPI IO0...5.\n
     *                 Reading back gives the last value written, NOT the input
     * value from the pins.\n If core 0 and core 1 both write to GPIO_HI_OUT
     * simultaneously (or to a SET/CLR/XOR alias),\n the result is as though
     * the write from core 0 took place first,\n and the write from core 1 was
     * then applied to that intermediate result.
     */
    inline void set_GPIO_HI_OUT_GPIO_HI_OUT(uint8_t value) volatile
    {
        uint32_t curr = GPIO_HI_OUT;

        curr &= ~(0b111111u << 0u);
        curr |= (value & 0b111111u) << 0u;

        GPIO_HI_OUT = curr;
    }

    /**
     * Set GPIO_HI_OUT_SET's GPIO_HI_OUT_SET field.
     *
     * Perform an atomic bit-set on GPIO_HI_OUT, i.e. `GPIO_HI_OUT |= wdata`
     */
    inline void set_GPIO_HI_OUT_SET_GPIO_HI_OUT_SET(uint8_t value) volatile
    {
        uint32_t curr = GPIO_HI_OUT_SET;

        curr &= ~(0b111111u << 0u);
        curr |= (value & 0b111111u) << 0u;

        GPIO_HI_OUT_SET = curr;
    }

    /**
     * Set GPIO_HI_OUT_CLR's GPIO_HI_OUT_CLR field.
     *
     * Perform an atomic bit-clear on GPIO_HI_OUT, i.e. `GPIO_HI_OUT &= ~wdata`
     */
    inline void set_GPIO_HI_OUT_CLR_GPIO_HI_OUT_CLR(uint8_t value) volatile
    {
        uint32_t curr = GPIO_HI_OUT_CLR;

        curr &= ~(0b111111u << 0u);
        curr |= (value & 0b111111u) << 0u;

        GPIO_HI_OUT_CLR = curr;
    }

    /**
     * Set GPIO_HI_OUT_XOR's GPIO_HI_OUT_XOR field.
     *
     * Perform an atomic bitwise XOR on GPIO_HI_OUT, i.e. `GPIO_HI_OUT ^=
     * wdata`
     */
    inline void set_GPIO_HI_OUT_XOR_GPIO_HI_OUT_XOR(uint8_t value) volatile
    {
        uint32_t curr = GPIO_HI_OUT_XOR;

        curr &= ~(0b111111u << 0u);
        curr |= (value & 0b111111u) << 0u;

        GPIO_HI_OUT_XOR = curr;
    }

    /**
     * Get GPIO_HI_OE's GPIO_HI_OE field.
     */
    inline uint8_t get_GPIO_HI_OE_GPIO_HI_OE() volatile
    {
        return (GPIO_HI_OE >> 0u) & 0b111111u;
    }

    /**
     * Set GPIO_HI_OE's GPIO_HI_OE field.
     *
     * Set output enable (1/0 -> output/input) for QSPI IO0...5.\n
     *                 Reading back gives the last value written.\n
     *                 If core 0 and core 1 both write to GPIO_HI_OE
     * simultaneously (or to a SET/CLR/XOR alias),\n the result is as though
     * the write from core 0 took place first,\n and the write from core 1 was
     * then applied to that intermediate result.
     */
    inline void set_GPIO_HI_OE_GPIO_HI_OE(uint8_t value) volatile
    {
        uint32_t curr = GPIO_HI_OE;

        curr &= ~(0b111111u << 0u);
        curr |= (value & 0b111111u) << 0u;

        GPIO_HI_OE = curr;
    }

    /**
     * Set GPIO_HI_OE_SET's GPIO_HI_OE_SET field.
     *
     * Perform an atomic bit-set on GPIO_HI_OE, i.e. `GPIO_HI_OE |= wdata`
     */
    inline void set_GPIO_HI_OE_SET_GPIO_HI_OE_SET(uint8_t value) volatile
    {
        uint32_t curr = GPIO_HI_OE_SET;

        curr &= ~(0b111111u << 0u);
        curr |= (value & 0b111111u) << 0u;

        GPIO_HI_OE_SET = curr;
    }

    /**
     * Set GPIO_HI_OE_CLR's GPIO_HI_OE_CLR field.
     *
     * Perform an atomic bit-clear on GPIO_HI_OE, i.e. `GPIO_HI_OE &= ~wdata`
     */
    inline void set_GPIO_HI_OE_CLR_GPIO_HI_OE_CLR(uint8_t value) volatile
    {
        uint32_t curr = GPIO_HI_OE_CLR;

        curr &= ~(0b111111u << 0u);
        curr |= (value & 0b111111u) << 0u;

        GPIO_HI_OE_CLR = curr;
    }

    /**
     * Set GPIO_HI_OE_XOR's GPIO_HI_OE_XOR field.
     *
     * Perform an atomic bitwise XOR on GPIO_HI_OE, i.e. `GPIO_HI_OE ^= wdata`
     */
    inline void set_GPIO_HI_OE_XOR_GPIO_HI_OE_XOR(uint8_t value) volatile
    {
        uint32_t curr = GPIO_HI_OE_XOR;

        curr &= ~(0b111111u << 0u);
        curr |= (value & 0b111111u) << 0u;

        GPIO_HI_OE_XOR = curr;
    }

    /**
     * Get FIFO_ST's VLD bit.
     */
    inline bool get_FIFO_ST_VLD() volatile
    {
        return FIFO_ST & (1u << 0u);
    }

    /**
     * Get FIFO_ST's RDY bit.
     */
    inline bool get_FIFO_ST_RDY() volatile
    {
        return FIFO_ST & (1u << 1u);
    }

    /**
     * Get FIFO_ST's WOF bit.
     */
    inline bool get_FIFO_ST_WOF() volatile
    {
        return FIFO_ST & (1u << 2u);
    }

    /**
     * Set FIFO_ST's WOF bit.
     *
     * Sticky flag indicating the TX FIFO was written when full. This write was
     * ignored by the FIFO.
     */
    inline void set_FIFO_ST_WOF() volatile
    {
        FIFO_ST |= 1u << 2u;
    }

    /**
     * Clear FIFO_ST's WOF bit.
     *
     * Sticky flag indicating the TX FIFO was written when full. This write was
     * ignored by the FIFO.
     */
    inline void clear_FIFO_ST_WOF() volatile
    {
        FIFO_ST &= ~(1u << 2u);
    }

    /**
     * Toggle FIFO_ST's WOF bit.
     *
     * Sticky flag indicating the TX FIFO was written when full. This write was
     * ignored by the FIFO.
     */
    inline void toggle_FIFO_ST_WOF() volatile
    {
        FIFO_ST ^= 1u << 2u;
    }

    /**
     * Get FIFO_ST's ROE bit.
     */
    inline bool get_FIFO_ST_ROE() volatile
    {
        return FIFO_ST & (1u << 3u);
    }

    /**
     * Set FIFO_ST's ROE bit.
     *
     * Sticky flag indicating the RX FIFO was read when empty. This read was
     * ignored by the FIFO.
     */
    inline void set_FIFO_ST_ROE() volatile
    {
        FIFO_ST |= 1u << 3u;
    }

    /**
     * Clear FIFO_ST's ROE bit.
     *
     * Sticky flag indicating the RX FIFO was read when empty. This read was
     * ignored by the FIFO.
     */
    inline void clear_FIFO_ST_ROE() volatile
    {
        FIFO_ST &= ~(1u << 3u);
    }

    /**
     * Toggle FIFO_ST's ROE bit.
     *
     * Sticky flag indicating the RX FIFO was read when empty. This read was
     * ignored by the FIFO.
     */
    inline void toggle_FIFO_ST_ROE() volatile
    {
        FIFO_ST ^= 1u << 3u;
    }

    /**
     * Get all of FIFO_ST's bit fields.
     */
    inline void get_FIFO_ST(bool &VLD, bool &RDY, bool &WOF,
                            bool &ROE) volatile
    {
        uint32_t curr = FIFO_ST;

        VLD = curr & (1u << 0u);
        RDY = curr & (1u << 1u);
        WOF = curr & (1u << 2u);
        ROE = curr & (1u << 3u);
    }

    /**
     * Set all of FIFO_ST's bit fields.
     *
     * (read-write) Status register for inter-core FIFOs (mailboxes).\n
     *             There is one FIFO in the core 0 -> core 1 direction, and one
     * core 1 -> core 0. Both are 32 bits wide and 8 words deep.\n Core 0 can
     * see the read side of the 1->0 FIFO (RX), and the write side of 0->1 FIFO
     * (TX).\n Core 1 can see the read side of the 0->1 FIFO (RX), and the
     * write side of 1->0 FIFO (TX).\n The SIO IRQ for each core is the logical
     * OR of the VLD, WOF and ROE fields of its FIFO_ST register.
     */
    inline void set_FIFO_ST(bool WOF, bool ROE) volatile
    {
        uint32_t curr = FIFO_ST;

        curr &= ~(0b1u << 2u);
        curr |= (WOF & 0b1u) << 2u;
        curr &= ~(0b1u << 3u);
        curr |= (ROE & 0b1u) << 3u;

        FIFO_ST = curr;
    }

    /**
     * Get DIV_CSR's READY bit.
     */
    inline bool get_DIV_CSR_READY() volatile
    {
        return DIV_CSR & (1u << 0u);
    }

    /**
     * Get DIV_CSR's DIRTY bit.
     */
    inline bool get_DIV_CSR_DIRTY() volatile
    {
        return DIV_CSR & (1u << 1u);
    }

    /**
     * Get all of DIV_CSR's bit fields.
     */
    inline void get_DIV_CSR(bool &READY, bool &DIRTY) volatile
    {
        uint32_t curr = DIV_CSR;

        READY = curr & (1u << 0u);
        DIRTY = curr & (1u << 1u);
    }

    /**
     * Get INTERP0_CTRL_LANE0's SHIFT field.
     */
    inline uint8_t get_INTERP0_CTRL_LANE0_SHIFT() volatile
    {
        return (INTERP0_CTRL_LANE0 >> 0u) & 0b11111u;
    }

    /**
     * Set INTERP0_CTRL_LANE0's SHIFT field.
     *
     * Logical right-shift applied to accumulator before masking
     */
    inline void set_INTERP0_CTRL_LANE0_SHIFT(uint8_t value) volatile
    {
        uint32_t curr = INTERP0_CTRL_LANE0;

        curr &= ~(0b11111u << 0u);
        curr |= (value & 0b11111u) << 0u;

        INTERP0_CTRL_LANE0 = curr;
    }

    /**
     * Get INTERP0_CTRL_LANE0's MASK_LSB field.
     */
    inline uint8_t get_INTERP0_CTRL_LANE0_MASK_LSB() volatile
    {
        return (INTERP0_CTRL_LANE0 >> 5u) & 0b11111u;
    }

    /**
     * Set INTERP0_CTRL_LANE0's MASK_LSB field.
     *
     * The least-significant bit allowed to pass by the mask (inclusive)
     */
    inline void set_INTERP0_CTRL_LANE0_MASK_LSB(uint8_t value) volatile
    {
        uint32_t curr = INTERP0_CTRL_LANE0;

        curr &= ~(0b11111u << 5u);
        curr |= (value & 0b11111u) << 5u;

        INTERP0_CTRL_LANE0 = curr;
    }

    /**
     * Get INTERP0_CTRL_LANE0's MASK_MSB field.
     */
    inline uint8_t get_INTERP0_CTRL_LANE0_MASK_MSB() volatile
    {
        return (INTERP0_CTRL_LANE0 >> 10u) & 0b11111u;
    }

    /**
     * Set INTERP0_CTRL_LANE0's MASK_MSB field.
     *
     * The most-significant bit allowed to pass by the mask (inclusive)\n
     *                 Setting MSB < LSB may cause chip to turn inside-out
     */
    inline void set_INTERP0_CTRL_LANE0_MASK_MSB(uint8_t value) volatile
    {
        uint32_t curr = INTERP0_CTRL_LANE0;

        curr &= ~(0b11111u << 10u);
        curr |= (value & 0b11111u) << 10u;

        INTERP0_CTRL_LANE0 = curr;
    }

    /**
     * Get INTERP0_CTRL_LANE0's SIGNED bit.
     */
    inline bool get_INTERP0_CTRL_LANE0_SIGNED() volatile
    {
        return INTERP0_CTRL_LANE0 & (1u << 15u);
    }

    /**
     * Set INTERP0_CTRL_LANE0's SIGNED bit.
     *
     * If SIGNED is set, the shifted and masked accumulator value is
     * sign-extended to 32 bits\n before adding to BASE0, and LANE0 PEEK/POP
     * appear extended to 32 bits when read by processor.
     */
    inline void set_INTERP0_CTRL_LANE0_SIGNED() volatile
    {
        INTERP0_CTRL_LANE0 |= 1u << 15u;
    }

    /**
     * Clear INTERP0_CTRL_LANE0's SIGNED bit.
     *
     * If SIGNED is set, the shifted and masked accumulator value is
     * sign-extended to 32 bits\n before adding to BASE0, and LANE0 PEEK/POP
     * appear extended to 32 bits when read by processor.
     */
    inline void clear_INTERP0_CTRL_LANE0_SIGNED() volatile
    {
        INTERP0_CTRL_LANE0 &= ~(1u << 15u);
    }

    /**
     * Toggle INTERP0_CTRL_LANE0's SIGNED bit.
     *
     * If SIGNED is set, the shifted and masked accumulator value is
     * sign-extended to 32 bits\n before adding to BASE0, and LANE0 PEEK/POP
     * appear extended to 32 bits when read by processor.
     */
    inline void toggle_INTERP0_CTRL_LANE0_SIGNED() volatile
    {
        INTERP0_CTRL_LANE0 ^= 1u << 15u;
    }

    /**
     * Get INTERP0_CTRL_LANE0's CROSS_INPUT bit.
     */
    inline bool get_INTERP0_CTRL_LANE0_CROSS_INPUT() volatile
    {
        return INTERP0_CTRL_LANE0 & (1u << 16u);
    }

    /**
     * Set INTERP0_CTRL_LANE0's CROSS_INPUT bit.
     *
     * If 1, feed the opposite lane's accumulator into this lane's shift + mask
     * hardware.\n Takes effect even if ADD_RAW is set (the CROSS_INPUT mux is
     * before the shift+mask bypass)
     */
    inline void set_INTERP0_CTRL_LANE0_CROSS_INPUT() volatile
    {
        INTERP0_CTRL_LANE0 |= 1u << 16u;
    }

    /**
     * Clear INTERP0_CTRL_LANE0's CROSS_INPUT bit.
     *
     * If 1, feed the opposite lane's accumulator into this lane's shift + mask
     * hardware.\n Takes effect even if ADD_RAW is set (the CROSS_INPUT mux is
     * before the shift+mask bypass)
     */
    inline void clear_INTERP0_CTRL_LANE0_CROSS_INPUT() volatile
    {
        INTERP0_CTRL_LANE0 &= ~(1u << 16u);
    }

    /**
     * Toggle INTERP0_CTRL_LANE0's CROSS_INPUT bit.
     *
     * If 1, feed the opposite lane's accumulator into this lane's shift + mask
     * hardware.\n Takes effect even if ADD_RAW is set (the CROSS_INPUT mux is
     * before the shift+mask bypass)
     */
    inline void toggle_INTERP0_CTRL_LANE0_CROSS_INPUT() volatile
    {
        INTERP0_CTRL_LANE0 ^= 1u << 16u;
    }

    /**
     * Get INTERP0_CTRL_LANE0's CROSS_RESULT bit.
     */
    inline bool get_INTERP0_CTRL_LANE0_CROSS_RESULT() volatile
    {
        return INTERP0_CTRL_LANE0 & (1u << 17u);
    }

    /**
     * Set INTERP0_CTRL_LANE0's CROSS_RESULT bit.
     *
     * If 1, feed the opposite lane's result into this lane's accumulator on
     * POP.
     */
    inline void set_INTERP0_CTRL_LANE0_CROSS_RESULT() volatile
    {
        INTERP0_CTRL_LANE0 |= 1u << 17u;
    }

    /**
     * Clear INTERP0_CTRL_LANE0's CROSS_RESULT bit.
     *
     * If 1, feed the opposite lane's result into this lane's accumulator on
     * POP.
     */
    inline void clear_INTERP0_CTRL_LANE0_CROSS_RESULT() volatile
    {
        INTERP0_CTRL_LANE0 &= ~(1u << 17u);
    }

    /**
     * Toggle INTERP0_CTRL_LANE0's CROSS_RESULT bit.
     *
     * If 1, feed the opposite lane's result into this lane's accumulator on
     * POP.
     */
    inline void toggle_INTERP0_CTRL_LANE0_CROSS_RESULT() volatile
    {
        INTERP0_CTRL_LANE0 ^= 1u << 17u;
    }

    /**
     * Get INTERP0_CTRL_LANE0's ADD_RAW bit.
     */
    inline bool get_INTERP0_CTRL_LANE0_ADD_RAW() volatile
    {
        return INTERP0_CTRL_LANE0 & (1u << 18u);
    }

    /**
     * Set INTERP0_CTRL_LANE0's ADD_RAW bit.
     *
     * If 1, mask + shift is bypassed for LANE0 result. This does not affect
     * FULL result.
     */
    inline void set_INTERP0_CTRL_LANE0_ADD_RAW() volatile
    {
        INTERP0_CTRL_LANE0 |= 1u << 18u;
    }

    /**
     * Clear INTERP0_CTRL_LANE0's ADD_RAW bit.
     *
     * If 1, mask + shift is bypassed for LANE0 result. This does not affect
     * FULL result.
     */
    inline void clear_INTERP0_CTRL_LANE0_ADD_RAW() volatile
    {
        INTERP0_CTRL_LANE0 &= ~(1u << 18u);
    }

    /**
     * Toggle INTERP0_CTRL_LANE0's ADD_RAW bit.
     *
     * If 1, mask + shift is bypassed for LANE0 result. This does not affect
     * FULL result.
     */
    inline void toggle_INTERP0_CTRL_LANE0_ADD_RAW() volatile
    {
        INTERP0_CTRL_LANE0 ^= 1u << 18u;
    }

    /**
     * Get INTERP0_CTRL_LANE0's FORCE_MSB field.
     */
    inline uint8_t get_INTERP0_CTRL_LANE0_FORCE_MSB() volatile
    {
        return (INTERP0_CTRL_LANE0 >> 19u) & 0b11u;
    }

    /**
     * Set INTERP0_CTRL_LANE0's FORCE_MSB field.
     *
     * ORed into bits 29:28 of the lane result presented to the processor on
     * the bus.\n No effect on the internal 32-bit datapath. Handy for using a
     * lane to generate sequence\n of pointers into flash or SRAM.
     */
    inline void set_INTERP0_CTRL_LANE0_FORCE_MSB(uint8_t value) volatile
    {
        uint32_t curr = INTERP0_CTRL_LANE0;

        curr &= ~(0b11u << 19u);
        curr |= (value & 0b11u) << 19u;

        INTERP0_CTRL_LANE0 = curr;
    }

    /**
     * Get INTERP0_CTRL_LANE0's BLEND bit.
     */
    inline bool get_INTERP0_CTRL_LANE0_BLEND() volatile
    {
        return INTERP0_CTRL_LANE0 & (1u << 21u);
    }

    /**
     * Set INTERP0_CTRL_LANE0's BLEND bit.
     *
     * Only present on INTERP0 on each core. If BLEND mode is enabled:\n
     *                 - LANE1 result is a linear interpolation between BASE0
     * and BASE1, controlled\n by the 8 LSBs of lane 1 shift and mask value (a
     * fractional number between\n 0 and 255/256ths)\n
     *                 - LANE0 result does not have BASE0 added (yields only
     * the 8 LSBs of lane 1 shift+mask value)\n
     *                 - FULL result does not have lane 1 shift+mask value
     * added (BASE2 + lane 0 shift+mask)\n LANE1 SIGNED flag controls whether
     * the interpolation is signed or unsigned.
     */
    inline void set_INTERP0_CTRL_LANE0_BLEND() volatile
    {
        INTERP0_CTRL_LANE0 |= 1u << 21u;
    }

    /**
     * Clear INTERP0_CTRL_LANE0's BLEND bit.
     *
     * Only present on INTERP0 on each core. If BLEND mode is enabled:\n
     *                 - LANE1 result is a linear interpolation between BASE0
     * and BASE1, controlled\n by the 8 LSBs of lane 1 shift and mask value (a
     * fractional number between\n 0 and 255/256ths)\n
     *                 - LANE0 result does not have BASE0 added (yields only
     * the 8 LSBs of lane 1 shift+mask value)\n
     *                 - FULL result does not have lane 1 shift+mask value
     * added (BASE2 + lane 0 shift+mask)\n LANE1 SIGNED flag controls whether
     * the interpolation is signed or unsigned.
     */
    inline void clear_INTERP0_CTRL_LANE0_BLEND() volatile
    {
        INTERP0_CTRL_LANE0 &= ~(1u << 21u);
    }

    /**
     * Toggle INTERP0_CTRL_LANE0's BLEND bit.
     *
     * Only present on INTERP0 on each core. If BLEND mode is enabled:\n
     *                 - LANE1 result is a linear interpolation between BASE0
     * and BASE1, controlled\n by the 8 LSBs of lane 1 shift and mask value (a
     * fractional number between\n 0 and 255/256ths)\n
     *                 - LANE0 result does not have BASE0 added (yields only
     * the 8 LSBs of lane 1 shift+mask value)\n
     *                 - FULL result does not have lane 1 shift+mask value
     * added (BASE2 + lane 0 shift+mask)\n LANE1 SIGNED flag controls whether
     * the interpolation is signed or unsigned.
     */
    inline void toggle_INTERP0_CTRL_LANE0_BLEND() volatile
    {
        INTERP0_CTRL_LANE0 ^= 1u << 21u;
    }

    /**
     * Get INTERP0_CTRL_LANE0's OVERF0 bit.
     */
    inline bool get_INTERP0_CTRL_LANE0_OVERF0() volatile
    {
        return INTERP0_CTRL_LANE0 & (1u << 23u);
    }

    /**
     * Get INTERP0_CTRL_LANE0's OVERF1 bit.
     */
    inline bool get_INTERP0_CTRL_LANE0_OVERF1() volatile
    {
        return INTERP0_CTRL_LANE0 & (1u << 24u);
    }

    /**
     * Get INTERP0_CTRL_LANE0's OVERF bit.
     */
    inline bool get_INTERP0_CTRL_LANE0_OVERF() volatile
    {
        return INTERP0_CTRL_LANE0 & (1u << 25u);
    }

    /**
     * Get all of INTERP0_CTRL_LANE0's bit fields.
     */
    inline void get_INTERP0_CTRL_LANE0(uint8_t &SHIFT, uint8_t &MASK_LSB,
                                       uint8_t &MASK_MSB, bool &SIGNED,
                                       bool &CROSS_INPUT, bool &CROSS_RESULT,
                                       bool &ADD_RAW, uint8_t &FORCE_MSB,
                                       bool &BLEND, bool &OVERF0, bool &OVERF1,
                                       bool &OVERF) volatile
    {
        uint32_t curr = INTERP0_CTRL_LANE0;

        SHIFT = (curr >> 0u) & 0b11111u;
        MASK_LSB = (curr >> 5u) & 0b11111u;
        MASK_MSB = (curr >> 10u) & 0b11111u;
        SIGNED = curr & (1u << 15u);
        CROSS_INPUT = curr & (1u << 16u);
        CROSS_RESULT = curr & (1u << 17u);
        ADD_RAW = curr & (1u << 18u);
        FORCE_MSB = (curr >> 19u) & 0b11u;
        BLEND = curr & (1u << 21u);
        OVERF0 = curr & (1u << 23u);
        OVERF1 = curr & (1u << 24u);
        OVERF = curr & (1u << 25u);
    }

    /**
     * Set all of INTERP0_CTRL_LANE0's bit fields.
     *
     * (read-write) Control register for lane 0
     */
    inline void set_INTERP0_CTRL_LANE0(uint8_t SHIFT, uint8_t MASK_LSB,
                                       uint8_t MASK_MSB, bool SIGNED,
                                       bool CROSS_INPUT, bool CROSS_RESULT,
                                       bool ADD_RAW, uint8_t FORCE_MSB,
                                       bool BLEND) volatile
    {
        uint32_t curr = INTERP0_CTRL_LANE0;

        curr &= ~(0b11111u << 0u);
        curr |= (SHIFT & 0b11111u) << 0u;
        curr &= ~(0b11111u << 5u);
        curr |= (MASK_LSB & 0b11111u) << 5u;
        curr &= ~(0b11111u << 10u);
        curr |= (MASK_MSB & 0b11111u) << 10u;
        curr &= ~(0b1u << 15u);
        curr |= (SIGNED & 0b1u) << 15u;
        curr &= ~(0b1u << 16u);
        curr |= (CROSS_INPUT & 0b1u) << 16u;
        curr &= ~(0b1u << 17u);
        curr |= (CROSS_RESULT & 0b1u) << 17u;
        curr &= ~(0b1u << 18u);
        curr |= (ADD_RAW & 0b1u) << 18u;
        curr &= ~(0b11u << 19u);
        curr |= (FORCE_MSB & 0b11u) << 19u;
        curr &= ~(0b1u << 21u);
        curr |= (BLEND & 0b1u) << 21u;

        INTERP0_CTRL_LANE0 = curr;
    }

    /**
     * Get INTERP0_CTRL_LANE1's SHIFT field.
     */
    inline uint8_t get_INTERP0_CTRL_LANE1_SHIFT() volatile
    {
        return (INTERP0_CTRL_LANE1 >> 0u) & 0b11111u;
    }

    /**
     * Set INTERP0_CTRL_LANE1's SHIFT field.
     *
     * Logical right-shift applied to accumulator before masking
     */
    inline void set_INTERP0_CTRL_LANE1_SHIFT(uint8_t value) volatile
    {
        uint32_t curr = INTERP0_CTRL_LANE1;

        curr &= ~(0b11111u << 0u);
        curr |= (value & 0b11111u) << 0u;

        INTERP0_CTRL_LANE1 = curr;
    }

    /**
     * Get INTERP0_CTRL_LANE1's MASK_LSB field.
     */
    inline uint8_t get_INTERP0_CTRL_LANE1_MASK_LSB() volatile
    {
        return (INTERP0_CTRL_LANE1 >> 5u) & 0b11111u;
    }

    /**
     * Set INTERP0_CTRL_LANE1's MASK_LSB field.
     *
     * The least-significant bit allowed to pass by the mask (inclusive)
     */
    inline void set_INTERP0_CTRL_LANE1_MASK_LSB(uint8_t value) volatile
    {
        uint32_t curr = INTERP0_CTRL_LANE1;

        curr &= ~(0b11111u << 5u);
        curr |= (value & 0b11111u) << 5u;

        INTERP0_CTRL_LANE1 = curr;
    }

    /**
     * Get INTERP0_CTRL_LANE1's MASK_MSB field.
     */
    inline uint8_t get_INTERP0_CTRL_LANE1_MASK_MSB() volatile
    {
        return (INTERP0_CTRL_LANE1 >> 10u) & 0b11111u;
    }

    /**
     * Set INTERP0_CTRL_LANE1's MASK_MSB field.
     *
     * The most-significant bit allowed to pass by the mask (inclusive)\n
     *                 Setting MSB < LSB may cause chip to turn inside-out
     */
    inline void set_INTERP0_CTRL_LANE1_MASK_MSB(uint8_t value) volatile
    {
        uint32_t curr = INTERP0_CTRL_LANE1;

        curr &= ~(0b11111u << 10u);
        curr |= (value & 0b11111u) << 10u;

        INTERP0_CTRL_LANE1 = curr;
    }

    /**
     * Get INTERP0_CTRL_LANE1's SIGNED bit.
     */
    inline bool get_INTERP0_CTRL_LANE1_SIGNED() volatile
    {
        return INTERP0_CTRL_LANE1 & (1u << 15u);
    }

    /**
     * Set INTERP0_CTRL_LANE1's SIGNED bit.
     *
     * If SIGNED is set, the shifted and masked accumulator value is
     * sign-extended to 32 bits\n before adding to BASE1, and LANE1 PEEK/POP
     * appear extended to 32 bits when read by processor.
     */
    inline void set_INTERP0_CTRL_LANE1_SIGNED() volatile
    {
        INTERP0_CTRL_LANE1 |= 1u << 15u;
    }

    /**
     * Clear INTERP0_CTRL_LANE1's SIGNED bit.
     *
     * If SIGNED is set, the shifted and masked accumulator value is
     * sign-extended to 32 bits\n before adding to BASE1, and LANE1 PEEK/POP
     * appear extended to 32 bits when read by processor.
     */
    inline void clear_INTERP0_CTRL_LANE1_SIGNED() volatile
    {
        INTERP0_CTRL_LANE1 &= ~(1u << 15u);
    }

    /**
     * Toggle INTERP0_CTRL_LANE1's SIGNED bit.
     *
     * If SIGNED is set, the shifted and masked accumulator value is
     * sign-extended to 32 bits\n before adding to BASE1, and LANE1 PEEK/POP
     * appear extended to 32 bits when read by processor.
     */
    inline void toggle_INTERP0_CTRL_LANE1_SIGNED() volatile
    {
        INTERP0_CTRL_LANE1 ^= 1u << 15u;
    }

    /**
     * Get INTERP0_CTRL_LANE1's CROSS_INPUT bit.
     */
    inline bool get_INTERP0_CTRL_LANE1_CROSS_INPUT() volatile
    {
        return INTERP0_CTRL_LANE1 & (1u << 16u);
    }

    /**
     * Set INTERP0_CTRL_LANE1's CROSS_INPUT bit.
     *
     * If 1, feed the opposite lane's accumulator into this lane's shift + mask
     * hardware.\n Takes effect even if ADD_RAW is set (the CROSS_INPUT mux is
     * before the shift+mask bypass)
     */
    inline void set_INTERP0_CTRL_LANE1_CROSS_INPUT() volatile
    {
        INTERP0_CTRL_LANE1 |= 1u << 16u;
    }

    /**
     * Clear INTERP0_CTRL_LANE1's CROSS_INPUT bit.
     *
     * If 1, feed the opposite lane's accumulator into this lane's shift + mask
     * hardware.\n Takes effect even if ADD_RAW is set (the CROSS_INPUT mux is
     * before the shift+mask bypass)
     */
    inline void clear_INTERP0_CTRL_LANE1_CROSS_INPUT() volatile
    {
        INTERP0_CTRL_LANE1 &= ~(1u << 16u);
    }

    /**
     * Toggle INTERP0_CTRL_LANE1's CROSS_INPUT bit.
     *
     * If 1, feed the opposite lane's accumulator into this lane's shift + mask
     * hardware.\n Takes effect even if ADD_RAW is set (the CROSS_INPUT mux is
     * before the shift+mask bypass)
     */
    inline void toggle_INTERP0_CTRL_LANE1_CROSS_INPUT() volatile
    {
        INTERP0_CTRL_LANE1 ^= 1u << 16u;
    }

    /**
     * Get INTERP0_CTRL_LANE1's CROSS_RESULT bit.
     */
    inline bool get_INTERP0_CTRL_LANE1_CROSS_RESULT() volatile
    {
        return INTERP0_CTRL_LANE1 & (1u << 17u);
    }

    /**
     * Set INTERP0_CTRL_LANE1's CROSS_RESULT bit.
     *
     * If 1, feed the opposite lane's result into this lane's accumulator on
     * POP.
     */
    inline void set_INTERP0_CTRL_LANE1_CROSS_RESULT() volatile
    {
        INTERP0_CTRL_LANE1 |= 1u << 17u;
    }

    /**
     * Clear INTERP0_CTRL_LANE1's CROSS_RESULT bit.
     *
     * If 1, feed the opposite lane's result into this lane's accumulator on
     * POP.
     */
    inline void clear_INTERP0_CTRL_LANE1_CROSS_RESULT() volatile
    {
        INTERP0_CTRL_LANE1 &= ~(1u << 17u);
    }

    /**
     * Toggle INTERP0_CTRL_LANE1's CROSS_RESULT bit.
     *
     * If 1, feed the opposite lane's result into this lane's accumulator on
     * POP.
     */
    inline void toggle_INTERP0_CTRL_LANE1_CROSS_RESULT() volatile
    {
        INTERP0_CTRL_LANE1 ^= 1u << 17u;
    }

    /**
     * Get INTERP0_CTRL_LANE1's ADD_RAW bit.
     */
    inline bool get_INTERP0_CTRL_LANE1_ADD_RAW() volatile
    {
        return INTERP0_CTRL_LANE1 & (1u << 18u);
    }

    /**
     * Set INTERP0_CTRL_LANE1's ADD_RAW bit.
     *
     * If 1, mask + shift is bypassed for LANE1 result. This does not affect
     * FULL result.
     */
    inline void set_INTERP0_CTRL_LANE1_ADD_RAW() volatile
    {
        INTERP0_CTRL_LANE1 |= 1u << 18u;
    }

    /**
     * Clear INTERP0_CTRL_LANE1's ADD_RAW bit.
     *
     * If 1, mask + shift is bypassed for LANE1 result. This does not affect
     * FULL result.
     */
    inline void clear_INTERP0_CTRL_LANE1_ADD_RAW() volatile
    {
        INTERP0_CTRL_LANE1 &= ~(1u << 18u);
    }

    /**
     * Toggle INTERP0_CTRL_LANE1's ADD_RAW bit.
     *
     * If 1, mask + shift is bypassed for LANE1 result. This does not affect
     * FULL result.
     */
    inline void toggle_INTERP0_CTRL_LANE1_ADD_RAW() volatile
    {
        INTERP0_CTRL_LANE1 ^= 1u << 18u;
    }

    /**
     * Get INTERP0_CTRL_LANE1's FORCE_MSB field.
     */
    inline uint8_t get_INTERP0_CTRL_LANE1_FORCE_MSB() volatile
    {
        return (INTERP0_CTRL_LANE1 >> 19u) & 0b11u;
    }

    /**
     * Set INTERP0_CTRL_LANE1's FORCE_MSB field.
     *
     * ORed into bits 29:28 of the lane result presented to the processor on
     * the bus.\n No effect on the internal 32-bit datapath. Handy for using a
     * lane to generate sequence\n of pointers into flash or SRAM.
     */
    inline void set_INTERP0_CTRL_LANE1_FORCE_MSB(uint8_t value) volatile
    {
        uint32_t curr = INTERP0_CTRL_LANE1;

        curr &= ~(0b11u << 19u);
        curr |= (value & 0b11u) << 19u;

        INTERP0_CTRL_LANE1 = curr;
    }

    /**
     * Get all of INTERP0_CTRL_LANE1's bit fields.
     */
    inline void get_INTERP0_CTRL_LANE1(uint8_t &SHIFT, uint8_t &MASK_LSB,
                                       uint8_t &MASK_MSB, bool &SIGNED,
                                       bool &CROSS_INPUT, bool &CROSS_RESULT,
                                       bool &ADD_RAW,
                                       uint8_t &FORCE_MSB) volatile
    {
        uint32_t curr = INTERP0_CTRL_LANE1;

        SHIFT = (curr >> 0u) & 0b11111u;
        MASK_LSB = (curr >> 5u) & 0b11111u;
        MASK_MSB = (curr >> 10u) & 0b11111u;
        SIGNED = curr & (1u << 15u);
        CROSS_INPUT = curr & (1u << 16u);
        CROSS_RESULT = curr & (1u << 17u);
        ADD_RAW = curr & (1u << 18u);
        FORCE_MSB = (curr >> 19u) & 0b11u;
    }

    /**
     * Set all of INTERP0_CTRL_LANE1's bit fields.
     *
     * (read-write) Control register for lane 1
     */
    inline void set_INTERP0_CTRL_LANE1(uint8_t SHIFT, uint8_t MASK_LSB,
                                       uint8_t MASK_MSB, bool SIGNED,
                                       bool CROSS_INPUT, bool CROSS_RESULT,
                                       bool ADD_RAW,
                                       uint8_t FORCE_MSB) volatile
    {
        uint32_t curr = INTERP0_CTRL_LANE1;

        curr &= ~(0b11111u << 0u);
        curr |= (SHIFT & 0b11111u) << 0u;
        curr &= ~(0b11111u << 5u);
        curr |= (MASK_LSB & 0b11111u) << 5u;
        curr &= ~(0b11111u << 10u);
        curr |= (MASK_MSB & 0b11111u) << 10u;
        curr &= ~(0b1u << 15u);
        curr |= (SIGNED & 0b1u) << 15u;
        curr &= ~(0b1u << 16u);
        curr |= (CROSS_INPUT & 0b1u) << 16u;
        curr &= ~(0b1u << 17u);
        curr |= (CROSS_RESULT & 0b1u) << 17u;
        curr &= ~(0b1u << 18u);
        curr |= (ADD_RAW & 0b1u) << 18u;
        curr &= ~(0b11u << 19u);
        curr |= (FORCE_MSB & 0b11u) << 19u;

        INTERP0_CTRL_LANE1 = curr;
    }

    /**
     * Get INTERP0_ACCUM0_ADD's INTERP0_ACCUM0_ADD field.
     */
    inline uint32_t get_INTERP0_ACCUM0_ADD_INTERP0_ACCUM0_ADD() volatile
    {
        return (INTERP0_ACCUM0_ADD >> 0u) & 0b111111111111111111111111u;
    }

    /**
     * Set INTERP0_ACCUM0_ADD's INTERP0_ACCUM0_ADD field.
     */
    inline void set_INTERP0_ACCUM0_ADD_INTERP0_ACCUM0_ADD(
        uint32_t value) volatile
    {
        uint32_t curr = INTERP0_ACCUM0_ADD;

        curr &= ~(0b111111111111111111111111u << 0u);
        curr |= (value & 0b111111111111111111111111u) << 0u;

        INTERP0_ACCUM0_ADD = curr;
    }

    /**
     * Get INTERP0_ACCUM1_ADD's INTERP0_ACCUM1_ADD field.
     */
    inline uint32_t get_INTERP0_ACCUM1_ADD_INTERP0_ACCUM1_ADD() volatile
    {
        return (INTERP0_ACCUM1_ADD >> 0u) & 0b111111111111111111111111u;
    }

    /**
     * Set INTERP0_ACCUM1_ADD's INTERP0_ACCUM1_ADD field.
     */
    inline void set_INTERP0_ACCUM1_ADD_INTERP0_ACCUM1_ADD(
        uint32_t value) volatile
    {
        uint32_t curr = INTERP0_ACCUM1_ADD;

        curr &= ~(0b111111111111111111111111u << 0u);
        curr |= (value & 0b111111111111111111111111u) << 0u;

        INTERP0_ACCUM1_ADD = curr;
    }

    /**
     * Get INTERP1_CTRL_LANE0's SHIFT field.
     */
    inline uint8_t get_INTERP1_CTRL_LANE0_SHIFT() volatile
    {
        return (INTERP1_CTRL_LANE0 >> 0u) & 0b11111u;
    }

    /**
     * Set INTERP1_CTRL_LANE0's SHIFT field.
     *
     * Logical right-shift applied to accumulator before masking
     */
    inline void set_INTERP1_CTRL_LANE0_SHIFT(uint8_t value) volatile
    {
        uint32_t curr = INTERP1_CTRL_LANE0;

        curr &= ~(0b11111u << 0u);
        curr |= (value & 0b11111u) << 0u;

        INTERP1_CTRL_LANE0 = curr;
    }

    /**
     * Get INTERP1_CTRL_LANE0's MASK_LSB field.
     */
    inline uint8_t get_INTERP1_CTRL_LANE0_MASK_LSB() volatile
    {
        return (INTERP1_CTRL_LANE0 >> 5u) & 0b11111u;
    }

    /**
     * Set INTERP1_CTRL_LANE0's MASK_LSB field.
     *
     * The least-significant bit allowed to pass by the mask (inclusive)
     */
    inline void set_INTERP1_CTRL_LANE0_MASK_LSB(uint8_t value) volatile
    {
        uint32_t curr = INTERP1_CTRL_LANE0;

        curr &= ~(0b11111u << 5u);
        curr |= (value & 0b11111u) << 5u;

        INTERP1_CTRL_LANE0 = curr;
    }

    /**
     * Get INTERP1_CTRL_LANE0's MASK_MSB field.
     */
    inline uint8_t get_INTERP1_CTRL_LANE0_MASK_MSB() volatile
    {
        return (INTERP1_CTRL_LANE0 >> 10u) & 0b11111u;
    }

    /**
     * Set INTERP1_CTRL_LANE0's MASK_MSB field.
     *
     * The most-significant bit allowed to pass by the mask (inclusive)\n
     *                 Setting MSB < LSB may cause chip to turn inside-out
     */
    inline void set_INTERP1_CTRL_LANE0_MASK_MSB(uint8_t value) volatile
    {
        uint32_t curr = INTERP1_CTRL_LANE0;

        curr &= ~(0b11111u << 10u);
        curr |= (value & 0b11111u) << 10u;

        INTERP1_CTRL_LANE0 = curr;
    }

    /**
     * Get INTERP1_CTRL_LANE0's SIGNED bit.
     */
    inline bool get_INTERP1_CTRL_LANE0_SIGNED() volatile
    {
        return INTERP1_CTRL_LANE0 & (1u << 15u);
    }

    /**
     * Set INTERP1_CTRL_LANE0's SIGNED bit.
     *
     * If SIGNED is set, the shifted and masked accumulator value is
     * sign-extended to 32 bits\n before adding to BASE0, and LANE0 PEEK/POP
     * appear extended to 32 bits when read by processor.
     */
    inline void set_INTERP1_CTRL_LANE0_SIGNED() volatile
    {
        INTERP1_CTRL_LANE0 |= 1u << 15u;
    }

    /**
     * Clear INTERP1_CTRL_LANE0's SIGNED bit.
     *
     * If SIGNED is set, the shifted and masked accumulator value is
     * sign-extended to 32 bits\n before adding to BASE0, and LANE0 PEEK/POP
     * appear extended to 32 bits when read by processor.
     */
    inline void clear_INTERP1_CTRL_LANE0_SIGNED() volatile
    {
        INTERP1_CTRL_LANE0 &= ~(1u << 15u);
    }

    /**
     * Toggle INTERP1_CTRL_LANE0's SIGNED bit.
     *
     * If SIGNED is set, the shifted and masked accumulator value is
     * sign-extended to 32 bits\n before adding to BASE0, and LANE0 PEEK/POP
     * appear extended to 32 bits when read by processor.
     */
    inline void toggle_INTERP1_CTRL_LANE0_SIGNED() volatile
    {
        INTERP1_CTRL_LANE0 ^= 1u << 15u;
    }

    /**
     * Get INTERP1_CTRL_LANE0's CROSS_INPUT bit.
     */
    inline bool get_INTERP1_CTRL_LANE0_CROSS_INPUT() volatile
    {
        return INTERP1_CTRL_LANE0 & (1u << 16u);
    }

    /**
     * Set INTERP1_CTRL_LANE0's CROSS_INPUT bit.
     *
     * If 1, feed the opposite lane's accumulator into this lane's shift + mask
     * hardware.\n Takes effect even if ADD_RAW is set (the CROSS_INPUT mux is
     * before the shift+mask bypass)
     */
    inline void set_INTERP1_CTRL_LANE0_CROSS_INPUT() volatile
    {
        INTERP1_CTRL_LANE0 |= 1u << 16u;
    }

    /**
     * Clear INTERP1_CTRL_LANE0's CROSS_INPUT bit.
     *
     * If 1, feed the opposite lane's accumulator into this lane's shift + mask
     * hardware.\n Takes effect even if ADD_RAW is set (the CROSS_INPUT mux is
     * before the shift+mask bypass)
     */
    inline void clear_INTERP1_CTRL_LANE0_CROSS_INPUT() volatile
    {
        INTERP1_CTRL_LANE0 &= ~(1u << 16u);
    }

    /**
     * Toggle INTERP1_CTRL_LANE0's CROSS_INPUT bit.
     *
     * If 1, feed the opposite lane's accumulator into this lane's shift + mask
     * hardware.\n Takes effect even if ADD_RAW is set (the CROSS_INPUT mux is
     * before the shift+mask bypass)
     */
    inline void toggle_INTERP1_CTRL_LANE0_CROSS_INPUT() volatile
    {
        INTERP1_CTRL_LANE0 ^= 1u << 16u;
    }

    /**
     * Get INTERP1_CTRL_LANE0's CROSS_RESULT bit.
     */
    inline bool get_INTERP1_CTRL_LANE0_CROSS_RESULT() volatile
    {
        return INTERP1_CTRL_LANE0 & (1u << 17u);
    }

    /**
     * Set INTERP1_CTRL_LANE0's CROSS_RESULT bit.
     *
     * If 1, feed the opposite lane's result into this lane's accumulator on
     * POP.
     */
    inline void set_INTERP1_CTRL_LANE0_CROSS_RESULT() volatile
    {
        INTERP1_CTRL_LANE0 |= 1u << 17u;
    }

    /**
     * Clear INTERP1_CTRL_LANE0's CROSS_RESULT bit.
     *
     * If 1, feed the opposite lane's result into this lane's accumulator on
     * POP.
     */
    inline void clear_INTERP1_CTRL_LANE0_CROSS_RESULT() volatile
    {
        INTERP1_CTRL_LANE0 &= ~(1u << 17u);
    }

    /**
     * Toggle INTERP1_CTRL_LANE0's CROSS_RESULT bit.
     *
     * If 1, feed the opposite lane's result into this lane's accumulator on
     * POP.
     */
    inline void toggle_INTERP1_CTRL_LANE0_CROSS_RESULT() volatile
    {
        INTERP1_CTRL_LANE0 ^= 1u << 17u;
    }

    /**
     * Get INTERP1_CTRL_LANE0's ADD_RAW bit.
     */
    inline bool get_INTERP1_CTRL_LANE0_ADD_RAW() volatile
    {
        return INTERP1_CTRL_LANE0 & (1u << 18u);
    }

    /**
     * Set INTERP1_CTRL_LANE0's ADD_RAW bit.
     *
     * If 1, mask + shift is bypassed for LANE0 result. This does not affect
     * FULL result.
     */
    inline void set_INTERP1_CTRL_LANE0_ADD_RAW() volatile
    {
        INTERP1_CTRL_LANE0 |= 1u << 18u;
    }

    /**
     * Clear INTERP1_CTRL_LANE0's ADD_RAW bit.
     *
     * If 1, mask + shift is bypassed for LANE0 result. This does not affect
     * FULL result.
     */
    inline void clear_INTERP1_CTRL_LANE0_ADD_RAW() volatile
    {
        INTERP1_CTRL_LANE0 &= ~(1u << 18u);
    }

    /**
     * Toggle INTERP1_CTRL_LANE0's ADD_RAW bit.
     *
     * If 1, mask + shift is bypassed for LANE0 result. This does not affect
     * FULL result.
     */
    inline void toggle_INTERP1_CTRL_LANE0_ADD_RAW() volatile
    {
        INTERP1_CTRL_LANE0 ^= 1u << 18u;
    }

    /**
     * Get INTERP1_CTRL_LANE0's FORCE_MSB field.
     */
    inline uint8_t get_INTERP1_CTRL_LANE0_FORCE_MSB() volatile
    {
        return (INTERP1_CTRL_LANE0 >> 19u) & 0b11u;
    }

    /**
     * Set INTERP1_CTRL_LANE0's FORCE_MSB field.
     *
     * ORed into bits 29:28 of the lane result presented to the processor on
     * the bus.\n No effect on the internal 32-bit datapath. Handy for using a
     * lane to generate sequence\n of pointers into flash or SRAM.
     */
    inline void set_INTERP1_CTRL_LANE0_FORCE_MSB(uint8_t value) volatile
    {
        uint32_t curr = INTERP1_CTRL_LANE0;

        curr &= ~(0b11u << 19u);
        curr |= (value & 0b11u) << 19u;

        INTERP1_CTRL_LANE0 = curr;
    }

    /**
     * Get INTERP1_CTRL_LANE0's CLAMP bit.
     */
    inline bool get_INTERP1_CTRL_LANE0_CLAMP() volatile
    {
        return INTERP1_CTRL_LANE0 & (1u << 22u);
    }

    /**
     * Set INTERP1_CTRL_LANE0's CLAMP bit.
     *
     * Only present on INTERP1 on each core. If CLAMP mode is enabled:\n
     *                 - LANE0 result is shifted and masked ACCUM0, clamped by
     * a lower bound of\n BASE0 and an upper bound of BASE1.\n
     *                 - Signedness of these comparisons is determined by
     * LANE0_CTRL_SIGNED
     */
    inline void set_INTERP1_CTRL_LANE0_CLAMP() volatile
    {
        INTERP1_CTRL_LANE0 |= 1u << 22u;
    }

    /**
     * Clear INTERP1_CTRL_LANE0's CLAMP bit.
     *
     * Only present on INTERP1 on each core. If CLAMP mode is enabled:\n
     *                 - LANE0 result is shifted and masked ACCUM0, clamped by
     * a lower bound of\n BASE0 and an upper bound of BASE1.\n
     *                 - Signedness of these comparisons is determined by
     * LANE0_CTRL_SIGNED
     */
    inline void clear_INTERP1_CTRL_LANE0_CLAMP() volatile
    {
        INTERP1_CTRL_LANE0 &= ~(1u << 22u);
    }

    /**
     * Toggle INTERP1_CTRL_LANE0's CLAMP bit.
     *
     * Only present on INTERP1 on each core. If CLAMP mode is enabled:\n
     *                 - LANE0 result is shifted and masked ACCUM0, clamped by
     * a lower bound of\n BASE0 and an upper bound of BASE1.\n
     *                 - Signedness of these comparisons is determined by
     * LANE0_CTRL_SIGNED
     */
    inline void toggle_INTERP1_CTRL_LANE0_CLAMP() volatile
    {
        INTERP1_CTRL_LANE0 ^= 1u << 22u;
    }

    /**
     * Get INTERP1_CTRL_LANE0's OVERF0 bit.
     */
    inline bool get_INTERP1_CTRL_LANE0_OVERF0() volatile
    {
        return INTERP1_CTRL_LANE0 & (1u << 23u);
    }

    /**
     * Get INTERP1_CTRL_LANE0's OVERF1 bit.
     */
    inline bool get_INTERP1_CTRL_LANE0_OVERF1() volatile
    {
        return INTERP1_CTRL_LANE0 & (1u << 24u);
    }

    /**
     * Get INTERP1_CTRL_LANE0's OVERF bit.
     */
    inline bool get_INTERP1_CTRL_LANE0_OVERF() volatile
    {
        return INTERP1_CTRL_LANE0 & (1u << 25u);
    }

    /**
     * Get all of INTERP1_CTRL_LANE0's bit fields.
     */
    inline void get_INTERP1_CTRL_LANE0(uint8_t &SHIFT, uint8_t &MASK_LSB,
                                       uint8_t &MASK_MSB, bool &SIGNED,
                                       bool &CROSS_INPUT, bool &CROSS_RESULT,
                                       bool &ADD_RAW, uint8_t &FORCE_MSB,
                                       bool &CLAMP, bool &OVERF0, bool &OVERF1,
                                       bool &OVERF) volatile
    {
        uint32_t curr = INTERP1_CTRL_LANE0;

        SHIFT = (curr >> 0u) & 0b11111u;
        MASK_LSB = (curr >> 5u) & 0b11111u;
        MASK_MSB = (curr >> 10u) & 0b11111u;
        SIGNED = curr & (1u << 15u);
        CROSS_INPUT = curr & (1u << 16u);
        CROSS_RESULT = curr & (1u << 17u);
        ADD_RAW = curr & (1u << 18u);
        FORCE_MSB = (curr >> 19u) & 0b11u;
        CLAMP = curr & (1u << 22u);
        OVERF0 = curr & (1u << 23u);
        OVERF1 = curr & (1u << 24u);
        OVERF = curr & (1u << 25u);
    }

    /**
     * Set all of INTERP1_CTRL_LANE0's bit fields.
     *
     * (read-write) Control register for lane 0
     */
    inline void set_INTERP1_CTRL_LANE0(uint8_t SHIFT, uint8_t MASK_LSB,
                                       uint8_t MASK_MSB, bool SIGNED,
                                       bool CROSS_INPUT, bool CROSS_RESULT,
                                       bool ADD_RAW, uint8_t FORCE_MSB,
                                       bool CLAMP) volatile
    {
        uint32_t curr = INTERP1_CTRL_LANE0;

        curr &= ~(0b11111u << 0u);
        curr |= (SHIFT & 0b11111u) << 0u;
        curr &= ~(0b11111u << 5u);
        curr |= (MASK_LSB & 0b11111u) << 5u;
        curr &= ~(0b11111u << 10u);
        curr |= (MASK_MSB & 0b11111u) << 10u;
        curr &= ~(0b1u << 15u);
        curr |= (SIGNED & 0b1u) << 15u;
        curr &= ~(0b1u << 16u);
        curr |= (CROSS_INPUT & 0b1u) << 16u;
        curr &= ~(0b1u << 17u);
        curr |= (CROSS_RESULT & 0b1u) << 17u;
        curr &= ~(0b1u << 18u);
        curr |= (ADD_RAW & 0b1u) << 18u;
        curr &= ~(0b11u << 19u);
        curr |= (FORCE_MSB & 0b11u) << 19u;
        curr &= ~(0b1u << 22u);
        curr |= (CLAMP & 0b1u) << 22u;

        INTERP1_CTRL_LANE0 = curr;
    }

    /**
     * Get INTERP1_CTRL_LANE1's SHIFT field.
     */
    inline uint8_t get_INTERP1_CTRL_LANE1_SHIFT() volatile
    {
        return (INTERP1_CTRL_LANE1 >> 0u) & 0b11111u;
    }

    /**
     * Set INTERP1_CTRL_LANE1's SHIFT field.
     *
     * Logical right-shift applied to accumulator before masking
     */
    inline void set_INTERP1_CTRL_LANE1_SHIFT(uint8_t value) volatile
    {
        uint32_t curr = INTERP1_CTRL_LANE1;

        curr &= ~(0b11111u << 0u);
        curr |= (value & 0b11111u) << 0u;

        INTERP1_CTRL_LANE1 = curr;
    }

    /**
     * Get INTERP1_CTRL_LANE1's MASK_LSB field.
     */
    inline uint8_t get_INTERP1_CTRL_LANE1_MASK_LSB() volatile
    {
        return (INTERP1_CTRL_LANE1 >> 5u) & 0b11111u;
    }

    /**
     * Set INTERP1_CTRL_LANE1's MASK_LSB field.
     *
     * The least-significant bit allowed to pass by the mask (inclusive)
     */
    inline void set_INTERP1_CTRL_LANE1_MASK_LSB(uint8_t value) volatile
    {
        uint32_t curr = INTERP1_CTRL_LANE1;

        curr &= ~(0b11111u << 5u);
        curr |= (value & 0b11111u) << 5u;

        INTERP1_CTRL_LANE1 = curr;
    }

    /**
     * Get INTERP1_CTRL_LANE1's MASK_MSB field.
     */
    inline uint8_t get_INTERP1_CTRL_LANE1_MASK_MSB() volatile
    {
        return (INTERP1_CTRL_LANE1 >> 10u) & 0b11111u;
    }

    /**
     * Set INTERP1_CTRL_LANE1's MASK_MSB field.
     *
     * The most-significant bit allowed to pass by the mask (inclusive)\n
     *                 Setting MSB < LSB may cause chip to turn inside-out
     */
    inline void set_INTERP1_CTRL_LANE1_MASK_MSB(uint8_t value) volatile
    {
        uint32_t curr = INTERP1_CTRL_LANE1;

        curr &= ~(0b11111u << 10u);
        curr |= (value & 0b11111u) << 10u;

        INTERP1_CTRL_LANE1 = curr;
    }

    /**
     * Get INTERP1_CTRL_LANE1's SIGNED bit.
     */
    inline bool get_INTERP1_CTRL_LANE1_SIGNED() volatile
    {
        return INTERP1_CTRL_LANE1 & (1u << 15u);
    }

    /**
     * Set INTERP1_CTRL_LANE1's SIGNED bit.
     *
     * If SIGNED is set, the shifted and masked accumulator value is
     * sign-extended to 32 bits\n before adding to BASE1, and LANE1 PEEK/POP
     * appear extended to 32 bits when read by processor.
     */
    inline void set_INTERP1_CTRL_LANE1_SIGNED() volatile
    {
        INTERP1_CTRL_LANE1 |= 1u << 15u;
    }

    /**
     * Clear INTERP1_CTRL_LANE1's SIGNED bit.
     *
     * If SIGNED is set, the shifted and masked accumulator value is
     * sign-extended to 32 bits\n before adding to BASE1, and LANE1 PEEK/POP
     * appear extended to 32 bits when read by processor.
     */
    inline void clear_INTERP1_CTRL_LANE1_SIGNED() volatile
    {
        INTERP1_CTRL_LANE1 &= ~(1u << 15u);
    }

    /**
     * Toggle INTERP1_CTRL_LANE1's SIGNED bit.
     *
     * If SIGNED is set, the shifted and masked accumulator value is
     * sign-extended to 32 bits\n before adding to BASE1, and LANE1 PEEK/POP
     * appear extended to 32 bits when read by processor.
     */
    inline void toggle_INTERP1_CTRL_LANE1_SIGNED() volatile
    {
        INTERP1_CTRL_LANE1 ^= 1u << 15u;
    }

    /**
     * Get INTERP1_CTRL_LANE1's CROSS_INPUT bit.
     */
    inline bool get_INTERP1_CTRL_LANE1_CROSS_INPUT() volatile
    {
        return INTERP1_CTRL_LANE1 & (1u << 16u);
    }

    /**
     * Set INTERP1_CTRL_LANE1's CROSS_INPUT bit.
     *
     * If 1, feed the opposite lane's accumulator into this lane's shift + mask
     * hardware.\n Takes effect even if ADD_RAW is set (the CROSS_INPUT mux is
     * before the shift+mask bypass)
     */
    inline void set_INTERP1_CTRL_LANE1_CROSS_INPUT() volatile
    {
        INTERP1_CTRL_LANE1 |= 1u << 16u;
    }

    /**
     * Clear INTERP1_CTRL_LANE1's CROSS_INPUT bit.
     *
     * If 1, feed the opposite lane's accumulator into this lane's shift + mask
     * hardware.\n Takes effect even if ADD_RAW is set (the CROSS_INPUT mux is
     * before the shift+mask bypass)
     */
    inline void clear_INTERP1_CTRL_LANE1_CROSS_INPUT() volatile
    {
        INTERP1_CTRL_LANE1 &= ~(1u << 16u);
    }

    /**
     * Toggle INTERP1_CTRL_LANE1's CROSS_INPUT bit.
     *
     * If 1, feed the opposite lane's accumulator into this lane's shift + mask
     * hardware.\n Takes effect even if ADD_RAW is set (the CROSS_INPUT mux is
     * before the shift+mask bypass)
     */
    inline void toggle_INTERP1_CTRL_LANE1_CROSS_INPUT() volatile
    {
        INTERP1_CTRL_LANE1 ^= 1u << 16u;
    }

    /**
     * Get INTERP1_CTRL_LANE1's CROSS_RESULT bit.
     */
    inline bool get_INTERP1_CTRL_LANE1_CROSS_RESULT() volatile
    {
        return INTERP1_CTRL_LANE1 & (1u << 17u);
    }

    /**
     * Set INTERP1_CTRL_LANE1's CROSS_RESULT bit.
     *
     * If 1, feed the opposite lane's result into this lane's accumulator on
     * POP.
     */
    inline void set_INTERP1_CTRL_LANE1_CROSS_RESULT() volatile
    {
        INTERP1_CTRL_LANE1 |= 1u << 17u;
    }

    /**
     * Clear INTERP1_CTRL_LANE1's CROSS_RESULT bit.
     *
     * If 1, feed the opposite lane's result into this lane's accumulator on
     * POP.
     */
    inline void clear_INTERP1_CTRL_LANE1_CROSS_RESULT() volatile
    {
        INTERP1_CTRL_LANE1 &= ~(1u << 17u);
    }

    /**
     * Toggle INTERP1_CTRL_LANE1's CROSS_RESULT bit.
     *
     * If 1, feed the opposite lane's result into this lane's accumulator on
     * POP.
     */
    inline void toggle_INTERP1_CTRL_LANE1_CROSS_RESULT() volatile
    {
        INTERP1_CTRL_LANE1 ^= 1u << 17u;
    }

    /**
     * Get INTERP1_CTRL_LANE1's ADD_RAW bit.
     */
    inline bool get_INTERP1_CTRL_LANE1_ADD_RAW() volatile
    {
        return INTERP1_CTRL_LANE1 & (1u << 18u);
    }

    /**
     * Set INTERP1_CTRL_LANE1's ADD_RAW bit.
     *
     * If 1, mask + shift is bypassed for LANE1 result. This does not affect
     * FULL result.
     */
    inline void set_INTERP1_CTRL_LANE1_ADD_RAW() volatile
    {
        INTERP1_CTRL_LANE1 |= 1u << 18u;
    }

    /**
     * Clear INTERP1_CTRL_LANE1's ADD_RAW bit.
     *
     * If 1, mask + shift is bypassed for LANE1 result. This does not affect
     * FULL result.
     */
    inline void clear_INTERP1_CTRL_LANE1_ADD_RAW() volatile
    {
        INTERP1_CTRL_LANE1 &= ~(1u << 18u);
    }

    /**
     * Toggle INTERP1_CTRL_LANE1's ADD_RAW bit.
     *
     * If 1, mask + shift is bypassed for LANE1 result. This does not affect
     * FULL result.
     */
    inline void toggle_INTERP1_CTRL_LANE1_ADD_RAW() volatile
    {
        INTERP1_CTRL_LANE1 ^= 1u << 18u;
    }

    /**
     * Get INTERP1_CTRL_LANE1's FORCE_MSB field.
     */
    inline uint8_t get_INTERP1_CTRL_LANE1_FORCE_MSB() volatile
    {
        return (INTERP1_CTRL_LANE1 >> 19u) & 0b11u;
    }

    /**
     * Set INTERP1_CTRL_LANE1's FORCE_MSB field.
     *
     * ORed into bits 29:28 of the lane result presented to the processor on
     * the bus.\n No effect on the internal 32-bit datapath. Handy for using a
     * lane to generate sequence\n of pointers into flash or SRAM.
     */
    inline void set_INTERP1_CTRL_LANE1_FORCE_MSB(uint8_t value) volatile
    {
        uint32_t curr = INTERP1_CTRL_LANE1;

        curr &= ~(0b11u << 19u);
        curr |= (value & 0b11u) << 19u;

        INTERP1_CTRL_LANE1 = curr;
    }

    /**
     * Get all of INTERP1_CTRL_LANE1's bit fields.
     */
    inline void get_INTERP1_CTRL_LANE1(uint8_t &SHIFT, uint8_t &MASK_LSB,
                                       uint8_t &MASK_MSB, bool &SIGNED,
                                       bool &CROSS_INPUT, bool &CROSS_RESULT,
                                       bool &ADD_RAW,
                                       uint8_t &FORCE_MSB) volatile
    {
        uint32_t curr = INTERP1_CTRL_LANE1;

        SHIFT = (curr >> 0u) & 0b11111u;
        MASK_LSB = (curr >> 5u) & 0b11111u;
        MASK_MSB = (curr >> 10u) & 0b11111u;
        SIGNED = curr & (1u << 15u);
        CROSS_INPUT = curr & (1u << 16u);
        CROSS_RESULT = curr & (1u << 17u);
        ADD_RAW = curr & (1u << 18u);
        FORCE_MSB = (curr >> 19u) & 0b11u;
    }

    /**
     * Set all of INTERP1_CTRL_LANE1's bit fields.
     *
     * (read-write) Control register for lane 1
     */
    inline void set_INTERP1_CTRL_LANE1(uint8_t SHIFT, uint8_t MASK_LSB,
                                       uint8_t MASK_MSB, bool SIGNED,
                                       bool CROSS_INPUT, bool CROSS_RESULT,
                                       bool ADD_RAW,
                                       uint8_t FORCE_MSB) volatile
    {
        uint32_t curr = INTERP1_CTRL_LANE1;

        curr &= ~(0b11111u << 0u);
        curr |= (SHIFT & 0b11111u) << 0u;
        curr &= ~(0b11111u << 5u);
        curr |= (MASK_LSB & 0b11111u) << 5u;
        curr &= ~(0b11111u << 10u);
        curr |= (MASK_MSB & 0b11111u) << 10u;
        curr &= ~(0b1u << 15u);
        curr |= (SIGNED & 0b1u) << 15u;
        curr &= ~(0b1u << 16u);
        curr |= (CROSS_INPUT & 0b1u) << 16u;
        curr &= ~(0b1u << 17u);
        curr |= (CROSS_RESULT & 0b1u) << 17u;
        curr &= ~(0b1u << 18u);
        curr |= (ADD_RAW & 0b1u) << 18u;
        curr &= ~(0b11u << 19u);
        curr |= (FORCE_MSB & 0b11u) << 19u;

        INTERP1_CTRL_LANE1 = curr;
    }

    /**
     * Get INTERP1_ACCUM0_ADD's INTERP1_ACCUM0_ADD field.
     */
    inline uint32_t get_INTERP1_ACCUM0_ADD_INTERP1_ACCUM0_ADD() volatile
    {
        return (INTERP1_ACCUM0_ADD >> 0u) & 0b111111111111111111111111u;
    }

    /**
     * Set INTERP1_ACCUM0_ADD's INTERP1_ACCUM0_ADD field.
     */
    inline void set_INTERP1_ACCUM0_ADD_INTERP1_ACCUM0_ADD(
        uint32_t value) volatile
    {
        uint32_t curr = INTERP1_ACCUM0_ADD;

        curr &= ~(0b111111111111111111111111u << 0u);
        curr |= (value & 0b111111111111111111111111u) << 0u;

        INTERP1_ACCUM0_ADD = curr;
    }

    /**
     * Get INTERP1_ACCUM1_ADD's INTERP1_ACCUM1_ADD field.
     */
    inline uint32_t get_INTERP1_ACCUM1_ADD_INTERP1_ACCUM1_ADD() volatile
    {
        return (INTERP1_ACCUM1_ADD >> 0u) & 0b111111111111111111111111u;
    }

    /**
     * Set INTERP1_ACCUM1_ADD's INTERP1_ACCUM1_ADD field.
     */
    inline void set_INTERP1_ACCUM1_ADD_INTERP1_ACCUM1_ADD(
        uint32_t value) volatile
    {
        uint32_t curr = INTERP1_ACCUM1_ADD;

        curr &= ~(0b111111111111111111111111u << 0u);
        curr |= (value & 0b111111111111111111111111u) << 0u;

        INTERP1_ACCUM1_ADD = curr;
    }
};

static_assert(sizeof(sio) == sio::size);

static volatile sio *const SIO = reinterpret_cast<sio *>(0xd0000000);

}; // namespace RP2040
